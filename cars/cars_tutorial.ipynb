{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482ae900",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"200\" align=\"right\"/>\n",
    "\n",
    "# CARS Tutorial\n",
    "\n",
    "CARS Team\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedc9b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "* Tutorial preparation\n",
    "* Context\n",
    "* How CARS works?\n",
    "* High level design\n",
    "* Quickstart\n",
    "* Command Line Interface examples\n",
    "* Step by step framework manipulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d703e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Tutorial preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31013ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preparation \n",
    "\n",
    "Prerequisites: \n",
    "```\n",
    "python >= 3.8\n",
    "python-venv or virtualenv\n",
    "gcc\n",
    "web access\n",
    "```     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2329f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cars install from pypi\n",
    "\n",
    "Follow CARS install: https://cars.readthedocs.io/en/latest/install.html\n",
    "\n",
    "VLFEAT install: \n",
    "```\n",
    "git clone https://github.com/CNES/vlfeat.git\n",
    "cd vlfeat && make && cd ..\n",
    "export CFLAGS=\"-I$PWD/vlfeat\"\n",
    "eport LDFLAGS=\"-L$PWD/vlfeat/bin/glnxa64\"\n",
    "export LD_LIBRARY_PATH=\"$PWD/vlfeat/bin/glnxa64:$LD_LIBRARY_PATH\"\n",
    "```\n",
    "\n",
    "CARS install: \n",
    "    \n",
    "```\n",
    "python -m venv venv # virtualenv venv init\n",
    "source ./venv/bin/activate # enter the virtualenv\n",
    "pip install --upgrade \"pip<=23.0.1\" \"numpy>=1.17.0\" cython\n",
    "pip install cars\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fab9c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jupyter notebook preparation\n",
    "\n",
    "Install Jupyter packages in previous virtualenv: \n",
    "\n",
    "```\n",
    "source ./venv/bin/activate # enter the virtualenv\n",
    "pip install notebook rise bokeh\n",
    "# add any tool you may need through pip install\n",
    "```\n",
    "\n",
    "Build Jupyter kernel:\n",
    "```\n",
    "python -m ipykernel install --sys-prefix --name=cars-kernel --display-name=cars-kernel\n",
    "```\n",
    "\n",
    "Jupyter environnement: \n",
    "``` \n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634cbdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af090c-9e82-49c9-bfd3-4e5c3c87f2db",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## CARS in a nutshell\n",
    "\n",
    "CARS produces Digital Surface Models from satellite imaging by photogrammetry.\n",
    "\n",
    "Main goals: \n",
    "\n",
    "- robust and distributed tool for operational pipelines.\n",
    "- capitalizing 3D developments\n",
    "- prototyping, tests, r&d evaluation\n",
    "\n",
    "*Be aware that CARS is new and evolving to maturity with CNES roadmaps*\n",
    "\n",
    "License:  Apache-2.0\n",
    "\n",
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"200\" align=\"right\"/>\n",
    "\n",
    "Web sites:\n",
    "\n",
    "- [https://github.com/cnes/cars/](https://github.com/cnes/cars/)\n",
    "- [https://cars.readthedocs.io/](https://cars.readthedocs.io/)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1212de7-f6cd-41ae-9501-0836e75fe39a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Projects context\n",
    "\n",
    "- [CO3D project](https://co3d.cnes.fr/en/co3d-0): four small satellites in the CO3D constellation to map the whole globe in 3D\n",
    "- [AI4GEO](https://www.ai4geo.eu/) : production of automatic 3D geospatial information based on AI technologies.\n",
    "- Internal studies, internships, phd, ...\n",
    "\n",
    "\n",
    "<img src=\"images/logo_co3D_cnes.jpg\" alt=\"CO3D logo\" width=\"200\" align=\"left\"/>\n",
    "<img src=\"images/logo_ai4geo.png\" alt=\"AI4GEO logo\" width=\"200\" align=\"right\" style=\"background-color:black;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5462fc9-b9b8-4c9f-8799-d29d4ad8a66b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Authors \n",
    "\n",
    "* David Youssefi <david.youssefi@cnes.fr>\n",
    "* Emmanuel Dubois <emmanuel.dubois@cnes.fr>\n",
    "* Emmanuelle Sarrazin <emmanuelle.sarrazin@cnes.fr>\n",
    "* Yoann Steux <yoann.steux@csgroup.eu>\n",
    "* Florian Douziech <florian.douziech@csgroup.eu>\n",
    "* Mathis Roux <mathis.roux@csgroup.eu>\n",
    "\n",
    "See [Authors.md](https://raw.githubusercontent.com/CNES/cars/master/AUTHORS.md) for full contributions in Github repository.\n",
    "\n",
    "### Copyright\n",
    "\n",
    "- CNES Copyright to ease maintenance with [Contributor License Aggrement](https://raw.githubusercontent.com/CNES/cars/master/docs/source/CLA/CCLA-CARS.doc)\n",
    "\n",
    "### Contributions\n",
    "\n",
    "See [Contributing.md](https://raw.githubusercontent.com/CNES/cars/master/CONTRIBUTING.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f0722-6acb-4bc2-987a-0264c101480f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Glossary\n",
    "\n",
    "DEM: Digital Elevation Model. Usually means all elevation models in raster: DSM, DTM,…\n",
    "\n",
    "DSM: Digital Surface Model. Represents the earth’s surface and includes all objects on it. CARS generates DSMs. \n",
    "\n",
    "DTM: Digital Terrain Model. Represents bare ground surface without any objects like plants and buildings.\n",
    "\n",
    "ROI: Region of Interest means a subpart of the DSM raster in CARS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b26e35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# How CARS works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3fdef3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Satellite photogrammetry\n",
    "\n",
    "<div style=\"position: relative; top: 0px; height: 350px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 5px; left: 0px; width: 280px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/satellites.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 280px; width: 520px; height: auto\">\n",
    "        <p> Indirect measure (same as eyes) by passive observation:<br>\n",
    "            Needs at least 2 images! </p>\n",
    "        <div style=\"text-align: center;\">\n",
    "            <img alt=\"image\" src=\"images/images.gif\" width=\"200px\">\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7641c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Satellite photogrammetry\n",
    "\n",
    "<div style=\"position: relative; top: 0px; height: 350px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 5px; left: 0px; width: 280px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/satellites.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 280px; width: 520px; height: auto\">\n",
    "        <p> Indirect measure (same as eyes) by passive observation:<br>\n",
    "            Needs at least 2 images and <b>geometric models</b>: </p>\n",
    "        <p> Rational Polynomial Coefficients (RPCs) provide a compact representation of a ground-to-image geometry giving a relationship between:\n",
    "            <ul>\n",
    "                <li>Image coordinates + altitude and ground coordinates (direct model: image to ground)</li>\n",
    "                <li>Ground coordinates + altitude and image coordinates (inverse model: ground to image)</li>\n",
    "            </ul> \n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc918d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Satellite photogrammetry\n",
    "\n",
    "<div style=\"position: relative; top: 0px; height: 350px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 5px; left: 0px; width: 280px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/satellites.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 280px; width: 520px; height: auto\">\n",
    "        <p> The photogrammetric processing can be performed without requiring a physical camera model. </p>\n",
    "        <p> These coefficients are classically contained in the RPC*XML files </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706cb3b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "- Images in same \"eyes\" geometry: lines are aligned and \n",
    "- Performance driven: 1 dimension research only\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image10.gif\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 85px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7fd9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "For each point in one image, find the corresponding point in the other image.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image13.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 145px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b0140",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "The resulting shifts are transformed into positions in the two images. <br>\n",
    "This allows us to deduce the lines of sight. The intersection of these lines gives a point in space: longitude.\n",
    "\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image16.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522f2e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "The resulting shifts are transformed into positions in the two images. <br>\n",
    "This allows us to deduce the lines of sight. The intersection of these lines gives a point in space: latitude.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image17.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8e0eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "The resulting shifts are transformed into positions in the two images. <br>\n",
    "This allows us to deduce the lines of sight. The intersection of these lines gives a point in space: altitude.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image19.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d702a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "The resulting shifts are transformed into positions in the two images. <br>\n",
    "This allows us to deduce the lines of sight. The intersection of these lines gives a point in space: altitude (single band pseudo color).\n",
    "\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image20.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7ac22",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "The resulting shifts are transformed into positions in the two images. <br>\n",
    "This allows us to deduce the lines of sight. The intersection of these lines gives a point in space: altitude (single band pseudo color and hillshade).\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image18.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130ecb0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "To obtain a raster image, the final process projects each point in a 2D grid: the altitudes.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image21.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 285px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97449d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Dense DSM\n",
    "\n",
    "To obtain a raster image, the final process projects each point in a 2D grid: the colors.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 300px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/dense.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 350px; width: 400px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/dense_steps/crop_image24.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 285px; left: 0px; width:320px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c0d2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Sparse DSM\n",
    "\n",
    "Matching can also be performed with keypoints (SIFT).\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 250px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/sparse.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: -50px; left: 210px; width: 600px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/sparse_steps/image25.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 145px; left: 0px; width:250px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9254181",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Sparse DSM\n",
    "\n",
    "Matching can also be performed with keypoints (SIFT).\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 250px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/sparse.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: -50px; left: 210px; width: 600px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/sparse_steps/image26.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 145px; left: 0px; width:250px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a9bdd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Sparse DSM\n",
    "\n",
    "The result is a sparse point cloud...\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 250px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/sparse.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 30px; left: 280px; width: 500px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/sparse_steps/image27.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:250px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3034f22",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Sparse DSM\n",
    "\n",
    "The result is a sparse point cloud...\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 250px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/sparse.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 30px; left: 280px; width: 500px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/sparse_steps/image28.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 215px; left: 0px; width:250px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d3635",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensor to Sparse DSM\n",
    "\n",
    "... and a sparse digital surface model.\n",
    "\n",
    "<div style=\"position: relative; top: 20px; height: 400px;\">\n",
    "    <div style=\"z-index: 10; position: absolute; top: 0px; left: 5px; width: 250px; height: auto\">\n",
    "        <img alt=\"dense_steps\" src=\"images/sparse.drawio.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 10; position: absolute; top: 30px; left: 280px; width: 500px; height: auto\">\n",
    "        <img alt=\"image\" src=\"images/sparse_steps/image29.png\">\n",
    "    </div>\n",
    "    <div style=\"z-index: 20; position: absolute; top: 285px; left: 0px; width:250px; height:60px; border: 3px solid #6C8EBF; border-radius: 10px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63da69-2348-4c7a-8085-52feb7c9d856",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# High level design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5aebe-6206-4ff9-a8a7-2f4001a4b286",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## CARS characteristics\n",
    "\n",
    "Objectives: \n",
    "- robust and performant methods for mass production.\n",
    "- state of the art algorithms\n",
    "- satellite data\n",
    "- distributed design\n",
    "- python3 and co when possible\n",
    "\n",
    "Technologies used :\n",
    "- Epipolar geometry\n",
    "- Input DTM\n",
    "- Scale Invariant Feature Transform (SIFT) sparse matching [1]\n",
    "- Semi Global Matching(SGM) matching optimization [2]\n",
    "\n",
    "[1] D. G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 2(60):91-110, 2004.\n",
    "\n",
    "[2] H. Hirschmuller, \"Stereo Processing by Semiglobal Matching and Mutual Information,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 2, pp. 328-341, Feb. 2008. doi: 10.1109/TPAMI.2007.1166\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897caa4f-96e4-479b-98d1-15fd0c8a6f36",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Main dependencies\n",
    "\n",
    "- Matching: Pandora and its libs: libsgm, libmc-cnn,...\n",
    "- Geometry: shareloc \n",
    "- Sparse matching: Vlfeat\n",
    "- Image libraries: rasterio, pyproj, Fiona, Shapely, NetCDF4\n",
    "- Data libraries: Numpy, Scipi, pandas, Affine, matplotlib.\n",
    "- Distributed and structure libraries: xarray, DASK, numba,\n",
    "- Python packaging,  code quality, documentation: setuptools, pylint, flake8, black, isort, pre-commit, sphinx, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50901d78-3048-49ac-8029-699c9633ef12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Orchestrator and distributed computing\n",
    "\n",
    "DASK framework can be used locally (local_dask) or through PBS on a HPC (pbs_dask).\n",
    "The orchestrator framework separates 3D pipeline from computing distribution. \n",
    "Features:\n",
    "- Memory dependent automatic computing of a tile size \n",
    "- Epipolar tiles and terrain tiles graph creation to distribute tile on nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dacab4-59ae-438c-9261-7bd9e76c7ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Command Line Interface\n",
    "\n",
    "```\n",
    "\n",
    "cars -h\n",
    "    \n",
    "usage: cars [-h] [--loglevel {DEBUG,INFO,PROGRESS,WARNING,ERROR,CRITICAL}] [--version] conf\n",
    "\n",
    "CARS: CNES Algorithms to Reconstruct Surface\n",
    "\n",
    "positional arguments:\n",
    "  conf                  Inputs Configuration File\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --loglevel {DEBUG,INFO,PROGRESS,WARNING,ERROR,CRITICAL}\n",
    "                        Logger level (default: WARNING. Should be one of (DEBUG, INFO, PROGRESS, WARNING, ERROR, CRITICAL)\n",
    "  --version, -v         show program's version number and exit\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc1307-d3b5-46f9-bd76-3fc664d73070",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## CARS Configuration : JSON\n",
    "\n",
    "```\n",
    "{\n",
    "    \"inputs\": {},\n",
    "    \"orchestrator\": {},\n",
    "    \"applications\": {},\n",
    "    \"output\": {},\n",
    "    \"pipeline\": \"pipeline_to_use\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7b83f-7c63-45e8-8123-c991dd0d86ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Pipelines \n",
    "\n",
    "Two possibilities: \n",
    "- **sensor_to_dense_dsm** : main pipeline for a dense high resolution DSM (see details after) (default)\n",
    "- **sensor_to_sparse_dsm** : produce a sparse low resolution DSM based on SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091019f-60a3-406b-9dc5-4436c54dba76",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Inputs \n",
    "Set sensors, geometric models, pairing, initial_elevation.\n",
    "\n",
    "       {\n",
    "        \"inputs\": {\n",
    "            \"sensors\" : {\n",
    "                \"one\": {\n",
    "                    \"image\": \"img1.tif\",\n",
    "                    \"geomodel\": \"img1.geom\",\n",
    "                    \"no_data\": 0\n",
    "                },\n",
    "                \"two\": {\n",
    "                    \"image\": \"img2.tif\",\n",
    "                    \"geomodel\": \"img2.geom\",\n",
    "                    \"no_data\": 0\n",
    "\n",
    "                }\n",
    "            },\n",
    "            \"pairing\": [[\"one\", \"two\"]],\n",
    "            \"initial_elevation\": \"srtm_dir/N29E031_KHEOPS.tif\"\n",
    "        },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c5d80-547f-494f-bc93-015d3079fbba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Applications\n",
    "\n",
    "Allows to redefine default parameters for each application used by pipeline and parameter the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80709e6-c3c7-428e-9bf2-da82bd391d41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Orchestrator\n",
    "Define orchestrator parameters that control the distributed computations:\n",
    "\n",
    "- mode: Parallelization mode “**local_dask**”, “pbs_dask” or “mp”\n",
    "\n",
    "- nb_workers: Number of workers \n",
    "\n",
    "- walltime: dependent on the mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf961c1-149f-4d8f-af42-6ea9e4c5036e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Output\n",
    "\n",
    "dependent on the pipeline. For main pipeline example:\n",
    "\n",
    "    \"output\": {\n",
    "          \"out_dir\": \"myoutputfolder\",\n",
    "          \"dsm_basename\": \"mydsm.tif\"\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27426288-e974-4b44-8723-83647b4e217f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img alt=\"sparse_matching_corrections\" src=\"images/sparse_matching_corrections.png\" align=\"right\" width=\"300\">\n",
    "\n",
    "## CARS 3D specifics\n",
    "\n",
    "- First SIFT Sparse matching steps for each pair:\n",
    "   - get vertical epipolar distribution to correct resampling\n",
    "   - get horizontal disparity distribution for dense matching step\n",
    "\n",
    "- use an adapted epipolar geometry : null disparity is based on a reference DTM (SRTM typically)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84dc580-de64-4640-9288-87c105b87ea4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img alt=\"Pandora logo\" src=\"images/logo_pandora.png\" align=\"right\" width=\"100\"><br>\n",
    "\n",
    "## Pandora dense matching pipeline\n",
    "\n",
    "- Independent toolbox inspired by [1]\n",
    "- Python implementation, except SGM C++ implementation\n",
    "- API or CLI\n",
    "\n",
    "Web site: [https://github.com/CNES/pandora](https://github.com/CNES/pandora)\n",
    "\n",
    "[1] A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms, D. Scharstein and R. Szeliski, vol. 47, International Journal of Computer Vision, 2002\n",
    "\n",
    "<img alt=\"pandora_overview\" src=\"images/pandora_overview.png\" align=\"left\" width=\"80%\"></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d85cab-4d04-4865-b53e-f0f8d62cca8c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img alt=\"Pandora logo\" src=\"images/logo_pandora.png\" align=\"right\" width=\"100\"><br>\n",
    "\n",
    "## Pandora dense matching pipeline details\n",
    "\n",
    "<img alt=\"pandora_pipeline\" src=\"images/pandora_pipeline.png\" align=\"right\" width=\"150\">\n",
    "<img alt=\"pandora_methods\" src=\"images/pandora_methods.png\" align=\"left\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf8135",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f37c6d-de1b-4cf4-9281-0a7290441a9d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Quickstart\n",
    "\n",
    "Download CARS Quick Start\n",
    "```\n",
    "mkdir /tmp/cars-tuto/\n",
    "cd /tmp/cars-tuto/\n",
    "wget https://raw.githubusercontent.com/CNES/cars/master/tutorials/quick_start_advanced.sh\n",
    "```\n",
    "\n",
    "Warning: Internet needed to download demo data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98908a26-1c98-466b-b06f-c9bcaabfa9c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Run the downloaded script\n",
    "```\n",
    "./quick_start_advanced.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30ebf8-8c21-4964-aaea-f1ec31bfd7ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "==== Demo CARS installed (advanced) =====\n",
    " \n",
    "- Cars must be installed:\n",
    "  # cars -v\n",
    "cars 0.7.0\n",
    " \n",
    "- Get and extract data samples from CARS repository [...]\n",
    "- Launch CARS with sensor_to_full_resolution_dsm pipeline for img1+img2 and img1+img3 pairs:\n",
    "  # cars configfile.json\n",
    "23-06-23 21:35:56 :: PROGRESS :: Check configuration...\n",
    "23-06-23 21:35:57 :: PROGRESS :: CARS pipeline is started.\n",
    "23-06-23 21:35:59 :: PROGRESS :: Data list to process: [ epi_matches_left ] ...\n",
    "Tiles processing: 100%|████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.21it/s]\n",
    "23-06-23 21:36:16 :: PROGRESS :: Data list to process: [ epi_matches_left ] ...\n",
    "Tiles processing: 100%|████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.41it/s]\n",
    "23-06-23 21:36:30 :: PROGRESS :: Data list to process: [ dsm , color ] ...\n",
    "Tiles processing: 100%|████████████████████████████████████████████████████████████| 4/4 [01:13<00:00, 18.35s/it]\n",
    "23-06-23 21:37:43 :: PROGRESS :: CARS has successfully completed the pipeline.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351eaa6-a688-4cf6-9411-b4863d675d30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "- Show resulting DSM:\n",
    "  # ls -al outresults/\n",
    "total 37556\n",
    "-rw-rw-r-- 1 youssefd youssefd      314 juin  23 21:37 23-06-23_21h35m_sensor_to_dense_dsm.log\n",
    "-rw-rw-r-- 1 youssefd youssefd 25166744 juin  23 21:37 clr.tif\n",
    "-rw-rw-r-- 1 youssefd youssefd     7268 juin  23 21:36 content.json\n",
    "-rw-rw-r-- 1 youssefd youssefd     9643 juin  23 21:35 dask_config_unknown.yaml\n",
    "-rw-rw-r-- 1 youssefd youssefd 16778119 juin  23 21:37 dsm.tif\n",
    "drwxrwxr-x 2 youssefd youssefd     4096 juin  23 21:37 one_three\n",
    "drwxrwxr-x 2 youssefd youssefd     4096 juin  23 21:37 one_two\n",
    "-rw-rw-r-- 1 youssefd youssefd     8151 juin  23 21:36 used_conf.json\n",
    "drwxrwxr-x 2 youssefd youssefd     4096 juin  23 21:35 workers_log\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86df17-3e56-49cc-b907-fb97058780da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Quick start results\n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"DSM\" src=\"images/dsm.png\" width=\"200\">\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Color\" src=\"images/clr.png\" width=\"200\">\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"MIX\" src=\"images/dsm_clr.png\" width=\"200\">\n",
    "  </p> \n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "    <em>dsm.tif</em>\n",
    "</td>\n",
    "<td>\n",
    "    <em>clr.tif</em>\n",
    "</td>\n",
    "<td>\n",
    "    <em>clr and dsm colored composition </em>\n",
    "</td> \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30844f38-90ac-4eaa-8de4-e37ad6f6c49c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Quick start details\n",
    "\n",
    "1. See input data\n",
    "   - sensor images + geometric models\n",
    "   - initial DTM (SRTM tile)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caecadfe-a751-48dd-a95f-a2280a78eeeb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Quick start details\n",
    "\n",
    "2. See configuration\n",
    "\n",
    "```\n",
    "cat data_gizeh/configfile.json\n",
    "```\n",
    "```\n",
    "{\n",
    "    \"inputs\": {\n",
    "        \"sensors\" : {\n",
    "            \"one\": {\n",
    "                \"image\": \"img1.tif\",\n",
    "                \"geomodel\": \"img1.geom\",\n",
    "\t\t\"color\": \"color1.tif\",\n",
    "                \"no_data\": 0\n",
    "            },\n",
    "            \"two\": {\n",
    "                \"image\": \"img2.tif\",\n",
    "                \"geomodel\": \"img2.geom\",\n",
    "                \"no_data\": 0\n",
    "\t    },\n",
    "            \"three\": {\n",
    "                \"image\": \"img3.tif\",\n",
    "                \"geomodel\": \"img3.geom\",\n",
    "                \"no_data\": 0\n",
    "            }\n",
    "        },\n",
    "        \"pairing\": [[\"one\", \"two\"],[\"one\", \"three\"]],\n",
    "        \"initial_elevation\": \"srtm_dir/N29E031_KHEOPS.tif\"\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"out_dir\": \"outresults\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca77c08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Command Line Interface examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe24115-1d0d-4ff2-bce0-4b6be416c2de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Logging\n",
    "Run CARS with more information: \n",
    "\n",
    "    cars --loglevel INFO configfile.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6647f2-d2da-4662-bc1b-2ef02aa848f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## CARS orchestration modification : nb_workers\n",
    "\n",
    "- Add orchestration configuration in input json file:\n",
    "\n",
    "        \"orchestrator\": {\n",
    "                \"mode\": \"local_dask\",\n",
    "                \"nb_workers\": 4\n",
    "        },\n",
    "\n",
    "\n",
    "- Run CARS again to see 4 workers : cars --loglevel INFO configfile.json \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b6795-a717-4ea9-9dca-ed05333c58c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## CARS orchestration modification: sequential mode\n",
    "\n",
    "- Add orchestration configuration in input json file:\n",
    "\n",
    "        \"orchestrator\": {\n",
    "                \"mode\": \"sequential\"\n",
    "        },\n",
    "\n",
    "\n",
    "- Run CARS again : cars --loglevel INFO configfile.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f1e48-40e7-42e0-ab2b-4fe1e157098b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Application configuration: save disparity maps\n",
    "\n",
    "- Add application configuration in input json file and define parameters for dense matching application\n",
    "\n",
    "        \"applications\": {\n",
    "                \"dense_matching\":{\n",
    "                        \"method\": \"census_sgm\",\n",
    "                        \"loader\": \"pandora\",\n",
    "                        \"save_disparity_map\": true\n",
    "                      }\n",
    "        },\n",
    "\n",
    "\n",
    "- Run CARS again : cars --loglevel INFO configfile.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d43cd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Application configuration: save disparity maps\n",
    "\n",
    "- Show resulting disparity maps\n",
    "\n",
    "\n",
    "```\n",
    "  # ls -l data_gizeh/outresults/\n",
    "     total 44580\n",
    "      -rw-r--r-- 1 carcars carcars        0 août   6 00:42 22-08-05_22h42m_sensor_to_full_res_dsm.log\n",
    "      -rw-r--r-- 1 carcars carcars 33555362 août   6 00:46 clr.tif\n",
    "      -rw-r--r-- 1 carcars carcars     9120 août   6 00:43 content.json\n",
    "      -rw-r--r-- 1 carcars carcars     7864 août   6 00:42 dask_config_unknown.yaml\n",
    "      -rw-r--r-- 1 carcars carcars 16778119 août   6 00:46 dsm.tif\n",
    "      drwxr-xr-x 2 carcars carcars     4096 août   6 00:46 one_three\n",
    "      drwxr-xr-x 2 carcars carcars     4096 août   6 00:46 one_two\n",
    "\n",
    "  # ls -l data_gizeh/outresults/one_two\n",
    "      -rw-r--r-- 1 carcars carcars     9120 août   6 00:43 epi_disp_color_left.tif\n",
    "      -rw-r--r-- 1 carcars carcars     7864 août   6 00:42 epi_disp_left.tif\n",
    "      -rw-r--r-- 1 carcars carcars 16778119 août   6 00:46 epi_disp_mask_left.tif\n",
    "  \n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0028585",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Application configuration: rasterization parameters\n",
    "\n",
    "- Add application configuration in input json file and define parameters for rasterization application\n",
    "\n",
    "        \"applications\": {\n",
    "             \"point_cloud_rasterization\": { \n",
    "                \"method\": \"simple_gaussian\",\n",
    "                \"dsm_radius\": 3,\n",
    "                \"sigma\": 0.3\n",
    "             }\n",
    "        },\n",
    "\n",
    "\n",
    "- Run CARS again : cars --loglevel INFO configfile.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f722ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/picto_transparent.png\" alt=\"CARS logo\" width=\"100\" align=\"right\"/>\n",
    "\n",
    "# Step by step framework manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62fb0a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Follow this link to access the slides: [sensor_to_dense_dsm_step_by_step.slides.html](https://cars-cnes.github.io/discover-cnes-3d-tools/cars/sensor_to_dense_dsm_step_by_step.slides.html#/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "41cef69d03cc8776cafbc952f48c668dc1c9a7aacaa94fd78ea743f1bb88c986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
